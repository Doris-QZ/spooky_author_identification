{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Doris-QZ/spooky_author_identification/blob/main/3_BERT_Spooky_Author_Identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bE1SFfbcvoF"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "This is the third deep learning model for the 'Spooky Author Identification' project. In this notebook, I will directly load the data from my Google Drive to fine-tune the **BERT model**. For the EDA section, please check the notebook: [1_LSTM_Spooky_Author_Identification.ipynb](https://github.com/Doris-QZ/spooky_author_identification/blob/main/1_LSTM_Spooky_Author_Identification.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmASOeD5pJwP",
        "outputId": "3123b306-ab25-4fe8-dc7a-48c0709ef10e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "stRH002pcvoI",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Load Important packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "import re\n",
        "\n",
        "# Modeling\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss, classification_report, accuracy_score, f1_score\n",
        "from torch.optim import AdamW"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "train = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/Spooky_Author_Identification/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/Spooky_Author_Identification/test.csv')"
      ],
      "metadata": {
        "id": "GDEHADmLTdGT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnxziDHxcvoT"
      },
      "source": [
        "### BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "CNbofuX2cvoT"
      },
      "outputs": [],
      "source": [
        "# Split the training set to training and validation set\n",
        "training_set, validation_set = train_test_split(train, test_size = 0.2, stratify = train['author_encoded'], random_state = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT model with last encoder layer and pooler layer unfreezed**\n",
        "\n",
        "I will first fine tune a BertForSequenceClassification model with the last encoder layer and pooler layer of BERT unfreezed."
      ],
      "metadata": {
        "id": "z08KAkEl9m2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load bert_tokenizer and bert_model\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEkn-xkLAuqu",
        "outputId": "94addc6b-53ef-4417-bd9d-e363ccf4d18a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the architecture of bert_model\n",
        "bert_model"
      ],
      "metadata": {
        "id": "tjJZfY8ZA5H8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8dc8a87-4070-4d40-f487-3e9827cf4aad"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use GPU if available\n",
        "bert_model = bert_model.to('cuda')"
      ],
      "metadata": {
        "id": "d-7Y_lajD5AW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze base model parameters\n",
        "for name, param in bert_model.base_model.named_parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "# Unfreeze the last encoder layer and pooiling layers\n",
        "for name, param in bert_model.base_model.encoder.layer[-1].named_parameters():\n",
        "  param.requires_grad = True\n",
        "for name, param in bert_model.base_model.pooler.named_parameters():\n",
        "  param.requires_grad = True"
      ],
      "metadata": {
        "id": "-1KuDD8KEI9A"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in bert_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in bert_model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'Total parameters: {total_params:,}')\n",
        "print(f'Trainable parameters: {trainable_params:,}')"
      ],
      "metadata": {
        "id": "-0XFLtu4nhUp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a7281d-51e5-4c65-840d-abdee8eb6ec8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 109,484,547\n",
            "Trainable parameters: 7,680,771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the length of text data\n",
        "text_length = training_set['text'].str.split().str.len()\n",
        "print(text_length.describe())"
      ],
      "metadata": {
        "id": "FeBPEg4BHGs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929d1a4d-a8b6-4809-ecc4-1853858a504f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    15663.000000\n",
            "mean        26.697951\n",
            "std         18.102614\n",
            "min          2.000000\n",
            "25%         15.000000\n",
            "50%         23.000000\n",
            "75%         34.000000\n",
            "max        594.000000\n",
            "Name: text, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(text_length > 64).sum() / training_set.shape[0]"
      ],
      "metadata": {
        "id": "DvaeAOyzHhSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50211a7b-5cfd-4454-d6cf-3f37609da70c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.033263104130754007)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 3% text data has more than 64 words. I will set the max_length of the bert_tokenizer to be 64."
      ],
      "metadata": {
        "id": "EFtQDxupH8uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize text data\n",
        "train_tokenized = bert_tokenizer(training_set['text'].tolist(),\n",
        "                                 padding = True,\n",
        "                                 truncation = True,\n",
        "                                 add_special_tokens = True,\n",
        "                                 max_length = 64,\n",
        "                                 return_tensors = 'pt')\n",
        "\n",
        "val_tokenized = bert_tokenizer(validation_set['text'].tolist(),\n",
        "                                 padding = True,\n",
        "                                 truncation = True,\n",
        "                                 add_special_tokens = True,\n",
        "                                 max_length = 64,\n",
        "                                 return_tensors = 'pt')"
      ],
      "metadata": {
        "id": "Tr-3pBxkIvSC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create torch dataset\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, tokenized, labels = None):\n",
        "    self.tokenized = tokenized\n",
        "    self.labels = labels\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    item = {key:value[idx] for key, value in self.tokenized.items()}\n",
        "    if self.labels:\n",
        "      item['labels'] = torch.tensor(self.labels[idx])\n",
        "    return item\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.tokenized['input_ids'])\n"
      ],
      "metadata": {
        "id": "D6ul81IVJTLB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset(train_tokenized, training_set['author_encoded'].tolist())\n",
        "val_dataset = Dataset(val_tokenized, validation_set['author_encoded'].tolist())"
      ],
      "metadata": {
        "id": "wvH49eAlMmxK"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA44F4g0DydB",
        "outputId": "df2cb491-b6c3-406a-a24f-0cf8d35b6106"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([  101, 10930, 11563,  2024, 14195,  2368,  1010,  2980, 18884,  1010,\n",
              "         26679,  6392, 24546,  1010, 10514,  2906,  8159,  1010,  1998, 10131,\n",
              "         18884,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0]),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'labels': tensor(0)}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define metrics\n",
        "def compute_metrics(eval_pred):\n",
        "  y_pred, y_true = eval_pred\n",
        "  y_pred = np.argmax(y_pred, axis = 1)\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "  f1 = f1_score(y_true, y_pred, average = 'macro')\n",
        "  return {'accuracy': accuracy, 'f1_score': f1}"
      ],
      "metadata": {
        "id": "nisL6jfqNebP"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define trainer\n",
        "args = TrainingArguments(\n",
        "    output_dir = '/content/drive/MyDrive/ColabNotebooks/Spooky_Author_Identification/bert_model',\n",
        "    num_train_epochs = 20,\n",
        "    learning_rate = 3e-5,\n",
        "    per_device_train_batch_size = 16,\n",
        "    per_device_eval_batch_size = 16,\n",
        "    eval_strategy = 'epoch',\n",
        "    logging_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    save_total_limit = 1,\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model = 'eval_loss',\n",
        "    report_to = \"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = bert_model,\n",
        "    args = args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = val_dataset,\n",
        "    compute_metrics = compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")"
      ],
      "metadata": {
        "id": "T1pXJ3LzRbyP"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "XLFWW1qFXv7v",
        "outputId": "80a788f4-f207-45f8-801b-5d21de934399"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6853' max='19580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 6853/19580 09:15 < 17:12, 12.33 it/s, Epoch 7/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.479700</td>\n",
              "      <td>0.483513</td>\n",
              "      <td>0.800306</td>\n",
              "      <td>0.800427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.441500</td>\n",
              "      <td>0.461761</td>\n",
              "      <td>0.814607</td>\n",
              "      <td>0.814128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.385900</td>\n",
              "      <td>0.474409</td>\n",
              "      <td>0.821246</td>\n",
              "      <td>0.821865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.338700</td>\n",
              "      <td>0.454556</td>\n",
              "      <td>0.829673</td>\n",
              "      <td>0.830116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.290200</td>\n",
              "      <td>0.478576</td>\n",
              "      <td>0.829162</td>\n",
              "      <td>0.829460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.252500</td>\n",
              "      <td>0.499073</td>\n",
              "      <td>0.829418</td>\n",
              "      <td>0.829714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.224800</td>\n",
              "      <td>0.504932</td>\n",
              "      <td>0.830184</td>\n",
              "      <td>0.829807</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6853, training_loss=0.34477200265280716, metrics={'train_runtime': 555.8315, 'train_samples_per_second': 563.588, 'train_steps_per_second': 35.227, 'total_flos': 3606002279139456.0, 'train_loss': 0.34477200265280716, 'epoch': 7.0})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "l7qWgnzm56xd",
        "outputId": "96187683-fd26-4a03-b794-47d145804668"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [245/245 00:13]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.4545561373233795,\n",
              " 'eval_accuracy': 0.8296731358529111,\n",
              " 'eval_f1_score': 0.8301157447653735,\n",
              " 'eval_runtime': 13.4984,\n",
              " 'eval_samples_per_second': 290.109,\n",
              " 'eval_steps_per_second': 18.15,\n",
              " 'epoch': 7.0}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best validation loss is 0.45, with an validation accuracy of 0.83 and f1 score of 0.83, achieved at epoch 7. As we can see from the training log, the training loss continually decreases over the 7 epochs, while the validation loss decreases for the first few epochs but starts increasing after epoch 4 and continues rising through epoch 7, indicating that the model is overfitting.  \n",
        "\n",
        "I also tried fine-tuning the model with only the pooler layer unfrozen, but it didn’t reduce overfitting. Instead, it lowered the performance, with a validation accuracy of around 0.77. Therefore, I decided to stick with the first model for making predictions on the test set."
      ],
      "metadata": {
        "id": "E0pvvx0h7eup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare test dataset\n",
        "test_tokenized = bert_tokenizer(test['text'].tolist(),\n",
        "                                 padding = True,\n",
        "                                 truncation = True,\n",
        "                                 add_special_tokens = True,\n",
        "                                 max_length = 64,\n",
        "                                 return_tensors = 'pt')\n",
        "\n",
        "test_dataset = Dataset(test_tokenized)"
      ],
      "metadata": {
        "id": "U0qe1VnaBPg6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the first model\n",
        "# output_dir = '/content/drive/MyDrive/ColabNotebooks/Spooky_Author_Identification/bert_model/checkpoint-9790'\n",
        "# bert_model = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "# bert_model = bert_model.to('cuda')"
      ],
      "metadata": {
        "id": "ymI3r-m5RxtN"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dummy training arguments\n",
        "args = TrainingArguments(\n",
        "    output_dir = '/content/drive/MyDrive/ColabNotebooks/Spooky_Author_Identification/bert_model/results',\n",
        "    per_device_eval_batch_size = 16,\n",
        "    report_to = \"none\"\n",
        ")\n",
        "\n",
        "# Create the trainer\n",
        "trainer = Trainer(\n",
        "    model = bert_model,\n",
        "    args = args\n",
        ")\n"
      ],
      "metadata": {
        "id": "KcpsVQcDDgCe"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the classification report on the validation set\n",
        "predictions = trainer.predict(val_dataset)\n",
        "y_pred = np.argmax(predictions.predictions, axis = 1)\n",
        "y_true = np.array(validation_set['author_encoded'])\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "sfE92ProI7BQ",
        "outputId": "0d6df1b3-12d7-4452-fb10-525f0cf54352"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82      1580\n",
            "           1       0.79      0.88      0.83      1209\n",
            "           2       0.83      0.83      0.83      1127\n",
            "\n",
            "    accuracy                           0.83      3916\n",
            "   macro avg       0.83      0.83      0.83      3916\n",
            "weighted avg       0.83      0.83      0.83      3916\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction on the test set\n",
        "predictions = trainer.predict(test_dataset)\n",
        "\n",
        "# Extract the logits from the prediction object\n",
        "logits = predictions.predictions\n",
        "\n",
        "# Convert logits to probability\n",
        "probabilities = torch.softmax(torch.tensor(logits), dim = -1).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PMyKE_mxIyPL",
        "outputId": "ea17ad6a-daaf-4175-8149-282bdf51063b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_prediction = pd.DataFrame(probabilities, columns = ['EAP', 'MWS', 'HPL'])\n",
        "bert_prediction = pd.concat([test['id'], bert_prediction], axis = 1)\n",
        "bert_prediction = bert_prediction[['id', 'EAP', 'HPL', 'MWS']]\n",
        "bert_prediction.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jiA9SGs7mGFg",
        "outputId": "a36092bf-27cb-44d7-a9a2-4bab5d3a4387"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id       EAP       HPL       MWS\n",
              "0  id02310  0.003493  0.000267  0.996240\n",
              "1  id24541  0.998931  0.000734  0.000335\n",
              "2  id00134  0.000129  0.999812  0.000059\n",
              "3  id27757  0.825461  0.171772  0.002767\n",
              "4  id04081  0.705251  0.218576  0.076173"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5ef78a3-f0a5-4dcd-adff-c06e1669d820\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>EAP</th>\n",
              "      <th>HPL</th>\n",
              "      <th>MWS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id02310</td>\n",
              "      <td>0.003493</td>\n",
              "      <td>0.000267</td>\n",
              "      <td>0.996240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id24541</td>\n",
              "      <td>0.998931</td>\n",
              "      <td>0.000734</td>\n",
              "      <td>0.000335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id00134</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.999812</td>\n",
              "      <td>0.000059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27757</td>\n",
              "      <td>0.825461</td>\n",
              "      <td>0.171772</td>\n",
              "      <td>0.002767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id04081</td>\n",
              "      <td>0.705251</td>\n",
              "      <td>0.218576</td>\n",
              "      <td>0.076173</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5ef78a3-f0a5-4dcd-adff-c06e1669d820')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e5ef78a3-f0a5-4dcd-adff-c06e1669d820 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e5ef78a3-f0a5-4dcd-adff-c06e1669d820');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e9390582-dead-40cb-89ee-b18bf7835333\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e9390582-dead-40cb-89ee-b18bf7835333')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e9390582-dead-40cb-89ee-b18bf7835333 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bert_prediction",
              "summary": "{\n  \"name\": \"bert_prediction\",\n  \"rows\": 8392,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8392,\n        \"samples\": [\n          \"id23707\",\n          \"id23391\",\n          \"id00343\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EAP\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 8388,\n        \"samples\": [\n          0.7238925099372864,\n          0.9895291924476624,\n          0.06331518292427063\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HPL\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 8380,\n        \"samples\": [\n          0.00035414265585131943,\n          0.00023419511853717268,\n          0.025139516219496727\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MWS\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 8374,\n        \"samples\": [\n          0.776596188545227,\n          0.01341610960662365,\n          0.0008768354309722781\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_prediction.to_csv('/content/drive/MyDrive/ColabNotebooks/Spooky_Author_Identification/bert_model/bert_prediction.csv', index = False)"
      ],
      "metadata": {
        "id": "yOYnvFRFKtDp"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After submitting to Kaggle, I got a public score of log_loss at 0.61, and private score of 0.57."
      ],
      "metadata": {
        "id": "i9yalE7uLv_-"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}